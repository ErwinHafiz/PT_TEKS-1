{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be89f130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pustaka berhasil diimpor.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Confirm all libraries are loaded\n",
    "print(\"✅ Pustaka berhasil diimpor.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e098b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stemmer dan Stopword Remover berhasil diinisialisasi.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Sastrawi stemmer and stopword remover\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword_remover = stopword_factory.create_stop_word_remover()\n",
    "\n",
    "# Confirm stemmer and stopword remover are initialized\n",
    "print(\"✅ Stemmer dan Stopword Remover berhasil diinisialisasi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb37cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adalah contoh kalimat banyak yang perlu timbang']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Define text preprocessing functions using Sastrawi\n",
    "\n",
    "def remove_headers_footers(text):\n",
    "    # Basic regular expression to remove common header/footer (watermarks, etc.)\n",
    "    text = re.sub(r'\\b(Mahkamah Agung|Nomor|Tanggal)\\b', '', text)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove punctuation, numbers, extra spaces\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}0-9]\", \"\", text)\n",
    "    text = ' '.join(text.split())  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "def sentence_tokenize(text):\n",
    "    # A simple sentence tokenizer based on punctuation\n",
    "    return re.split(r'(?<!\\w\\.\\w.)(?<=\\.|\\?)\\s', text)\n",
    "\n",
    "def apply_stemming(sentence):\n",
    "    # Apply Sastrawi stemmer to the sentence\n",
    "    return ' '.join([stemmer.stem(word) for word in sentence.split()])\n",
    "\n",
    "def preprocess_text_with_sastrawi(text):\n",
    "    # Remove non-text elements like watermarks, header/footer\n",
    "    text = remove_headers_footers(text)\n",
    "    \n",
    "    # Tokenization and cleaning\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Tokenize sentences and words\n",
    "    sentences = sentence_tokenize(text)\n",
    "    \n",
    "    # Apply stemming using Sastrawi\n",
    "    stemmed_sentences = [apply_stemming(sentence) for sentence in sentences]\n",
    "    \n",
    "    # Remove stopwords using Sastrawi stopword remover\n",
    "    cleaned_sentences = [stopword_remover.remove(sentence) for sentence in stemmed_sentences]\n",
    "    \n",
    "    return cleaned_sentences\n",
    "\n",
    "# Test preprocessing with a sample text\n",
    "sample_text = \"Ini adalah contoh kalimat. Ada banyak hal yang perlu dipertimbangkan.\"\n",
    "processed_sample = preprocess_text_with_sastrawi(sample_text)\n",
    "processed_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb921c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37796447, 0.37796447, 0.37796447, 0.37796447, 0.37796447,\n",
       "        0.37796447, 0.37796447]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: TF-IDF Calculation\n",
    "\n",
    "def compute_tfidf(sentences):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    return tfidf_matrix, vectorizer\n",
    "\n",
    "# Test TF-IDF on processed sample text\n",
    "tfidf_matrix, vectorizer = compute_tfidf(processed_sample)\n",
    "tfidf_matrix.toarray()  # Display the TF-IDF matrix as an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd8f2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Cosine Similarity Calculation\n",
    "\n",
    "def cosine_similarity(tfidf_matrix):\n",
    "    cosine_similarities = np.dot(tfidf_matrix, tfidf_matrix.T).toarray()\n",
    "    return cosine_similarities\n",
    "\n",
    "# Calculate cosine similarity for the sample text's TF-IDF matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "cosine_sim  # Display cosine similarity matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b447f678",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'from_numpy_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(ranked_sentences)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Apply TextRank on processed sample text\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m generated_summary = \u001b[43mtextrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_sim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m generated_summary\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtextrank\u001b[39m\u001b[34m(cosine_similarities, sentences, top_n)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtextrank\u001b[39m(cosine_similarities, sentences, top_n=\u001b[32m5\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Create similarity graph\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     nx_graph = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy_matrix\u001b[49m(cosine_similarities)\n\u001b[32m      6\u001b[39m     scores = nx.pagerank(nx_graph)  \u001b[38;5;66;03m# Compute TextRank scores\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Rank sentences based on the TextRank scores\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'networkx' has no attribute 'from_numpy_matrix'"
     ]
    }
   ],
   "source": [
    "# Step 4: TextRank Algorithm with Explanation of Sentence Ranking\n",
    "\n",
    "def textrank(cosine_similarities, sentences, top_n=5):\n",
    "    # Create similarity graph\n",
    "    nx_graph = nx.from_numpy_matrix(cosine_similarities)\n",
    "    scores = nx.pagerank(nx_graph)  # Compute TextRank scores\n",
    "    \n",
    "    # Rank sentences based on the TextRank scores\n",
    "    ranked_sentences = [sentences[i] for i in sorted(scores, key=scores.get, reverse=True)[:top_n]]\n",
    "    \n",
    "    # Display ranking information for analysis\n",
    "    ranked_info = [(sentences[i], scores[i]) for i in sorted(scores, key=scores.get, reverse=True)]\n",
    "    print(\"\\nRanking of Sentences Based on TextRank Scores:\")\n",
    "    for rank, (sentence, score) in enumerate(ranked_info, 1):\n",
    "        print(f\"Rank {rank}: Score {score:.4f} | Sentence: {sentence[:100]}...\")\n",
    "\n",
    "    return ' '.join(ranked_sentences)\n",
    "\n",
    "# Apply TextRank on processed sample text\n",
    "generated_summary = textrank(cosine_sim, processed_sample, top_n=3)\n",
    "generated_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b638195d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Evaluate using ROUGE\u001b[39;00m\n\u001b[32m      9\u001b[39m reference_summary = \u001b[33m\"\u001b[39m\u001b[33mIni adalah ringkasan referensi yang dibuat oleh ahli.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m rouge_scores = evaluate_rouge(reference_summary, \u001b[43mgenerated_summary\u001b[49m)\n\u001b[32m     11\u001b[39m rouge_scores\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Step 6: Precision, Recall, F-Measure Calculation\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'generated_summary' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 5: ROUGE Evaluation\n",
    "\n",
    "def evaluate_rouge(reference_summary, generated_summary):\n",
    "    scorer = rouge_scorer.RougeScorer(metrics=['rouge1', 'rouge2', 'rougeL'], lang='en')\n",
    "    scores = scorer.score(reference_summary, generated_summary)\n",
    "    return scores\n",
    "\n",
    "# Evaluate using ROUGE\n",
    "reference_summary = \"Ini adalah ringkasan referensi yang dibuat oleh ahli.\"\n",
    "rouge_scores = evaluate_rouge(reference_summary, generated_summary)\n",
    "rouge_scores\n",
    "\n",
    "\n",
    "# Step 6: Precision, Recall, F-Measure Calculation\n",
    "\n",
    "def evaluate_precision_recall_fmeasure(reference_summary, generated_summary):\n",
    "    reference_tokens = set(reference_summary.split())\n",
    "    generated_tokens = set(generated_summary.split())\n",
    "    \n",
    "    true_positive = len(reference_tokens & generated_tokens)\n",
    "    false_positive = len(generated_tokens - reference_tokens)\n",
    "    false_negative = len(reference_tokens - generated_tokens)\n",
    "    \n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f_measure\n",
    "\n",
    "# Evaluate using Precision, Recall, F-Measure\n",
    "precision, recall, f_measure = evaluate_precision_recall_fmeasure(reference_summary, generated_summary)\n",
    "precision, recall, f_measure\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDBQdrant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
