{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf9f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PyPDF2\n",
    "import networkx as nx\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from rouge_score import rouge_scorer  # Pustaka untuk ROUGE evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289f79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fungsi untuk mengekstrak teks dari file PDF (jika diperlukan)\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in range(len(reader.pages)):\n",
    "            text += reader.pages[page].extract_text()\n",
    "    return text\n",
    "\n",
    "# Fungsi untuk membersihkan teks (hapus header/footer/watermark)\n",
    "def clean_text(text):\n",
    "    # Menghapus header, footer, watermark menggunakan regex\n",
    "    text = re.sub(r'Header Pattern', '', text)\n",
    "    text = re.sub(r'Footer Pattern', '', text)\n",
    "    text = re.sub(r'Watermark Pattern', '', text)\n",
    "    return text\n",
    "\n",
    "# Fungsi untuk stemming\n",
    "def apply_stemming(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "# Fungsi untuk menghapus stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Fungsi untuk preprocessing teks (tokenisasi, stemming, stopwords removal)\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    stemmed_text = apply_stemming(cleaned_text)\n",
    "    final_text = remove_stopwords(stemmed_text)\n",
    "    return final_text\n",
    "\n",
    "# Fungsi untuk memproses dokumen dalam folder\n",
    "def process_txt_files_in_folder(folder_path):\n",
    "    all_texts = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                processed_text = preprocess_text(text)\n",
    "                all_texts.append(processed_text)\n",
    "                filenames.append(filename)\n",
    "    return all_texts, filenames\n",
    "\n",
    "# Fungsi untuk menghitung TF-IDF\n",
    "def compute_tfidf(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    return tfidf_matrix\n",
    "\n",
    "# Fungsi untuk menghitung cosine similarity antara kalimat-kalimat\n",
    "def compute_cosine_similarity(tfidf_matrix):\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return cosine_sim_matrix\n",
    "\n",
    "# Fungsi untuk menerapkan algoritma TextRank\n",
    "def textrank_summarize(texts):\n",
    "    # Tokenisasi kalimat\n",
    "    sentences = [sent_tokenize(text) for text in texts]\n",
    "    flattened_sentences = [sentence for sublist in sentences for sentence in sublist]\n",
    "    \n",
    "    # Menghitung TF-IDF\n",
    "    tfidf_matrix = compute_tfidf(flattened_sentences)\n",
    "    \n",
    "    # Menghitung cosine similarity antar kalimat\n",
    "    cosine_sim_matrix = compute_cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Membangun graf berdasarkan cosine similarity\n",
    "    graph = nx.from_numpy_array(cosine_sim_matrix)\n",
    "    scores = nx.pagerank(graph)\n",
    "    \n",
    "    # Menyusun kalimat berdasarkan skor tertinggi\n",
    "    ranked_sentences = sorted(((score, idx) for idx, score in scores.items()), reverse=True)\n",
    "    \n",
    "    summary = ' '.join([flattened_sentences[idx] for score, idx in ranked_sentences[:5]])  # Ambil 5 kalimat teratas\n",
    "    return summary, flattened_sentences  # Mengembalikan kalimat terpilih untuk evaluasi\n",
    "\n",
    "# Fungsi untuk menghitung evaluasi Precision, Recall, dan F-measure\n",
    "def calculate_precision_recall_f1(true_summary, generated_summary):\n",
    "    true_set = set(true_summary.split())\n",
    "    generated_set = set(generated_summary.split())\n",
    "    \n",
    "    # Precision\n",
    "    precision = len(true_set.intersection(generated_set)) / len(generated_set) if generated_set else 0\n",
    "    \n",
    "    # Recall\n",
    "    recall = len(true_set.intersection(generated_set)) / len(true_set) if true_set else 0\n",
    "    \n",
    "    # F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Fungsi untuk menghitung ROUGE\n",
    "def calculate_rouge(true_summary, generated_summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(true_summary, generated_summary)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709bf809",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_putusan/dok_putusan_txt\\\\referensi_ringkasan\\\\doc01.txt_ref.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Membaca ringkasan referensi dari file referensi_ringkasan (asumsikan file ini tersedia)\u001b[39;00m\n\u001b[32m     18\u001b[39m reference_summary_path = os.path.join(folder_path, \u001b[33m'\u001b[39m\u001b[33mreferensi_ringkasan\u001b[39m\u001b[33m'\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilenames[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_ref.txt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreference_summary_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ref_file:\n\u001b[32m     20\u001b[39m     reference_summary = ref_file.read().strip()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Evaluasi dengan Precision, Recall, F1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\VDBQdrant\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:327\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data_putusan/dok_putusan_txt\\\\referensi_ringkasan\\\\doc01.txt_ref.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Contoh penggunaan untuk folder teks yang sudah diproses\n",
    "folder_path = 'data_putusan/dok_putusan_txt'  # Ganti dengan path folder yang berisi dokumen putusan dalam format .txt\n",
    "texts, filenames = process_txt_files_in_folder(folder_path)\n",
    "\n",
    "# Menyaring dan merangkum setiap dokumen, serta mengevaluasi hasilnya\n",
    "summaries = {}\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "f1_all = []\n",
    "rouge_scores = []\n",
    "\n",
    "for idx, text in enumerate(texts):\n",
    "    # Hasil peringkasan untuk setiap dokumen\n",
    "    summary, flattened_sentences = textrank_summarize([text])  # Peringkasan untuk setiap dokumen\n",
    "    summaries[filenames[idx]] = summary\n",
    "    \n",
    "    # Membaca ringkasan referensi dari file referensi_ringkasan (asumsikan file ini tersedia)\n",
    "    reference_summary_path = os.path.join(folder_path, 'referensi_ringkasan', f'{filenames[idx]}_ref.txt')\n",
    "    with open(reference_summary_path, 'r', encoding='utf-8') as ref_file:\n",
    "        reference_summary = ref_file.read().strip()\n",
    "\n",
    "    # Evaluasi dengan Precision, Recall, F1\n",
    "    precision, recall, f1 = calculate_precision_recall_f1(reference_summary, summary)\n",
    "    precision_all.append(precision)\n",
    "    recall_all.append(recall)\n",
    "    f1_all.append(f1)\n",
    "\n",
    "    # Evaluasi dengan ROUGE\n",
    "    rouge_score = calculate_rouge(reference_summary, summary)\n",
    "    rouge_scores.append(rouge_score)\n",
    "\n",
    "# Menampilkan hasil evaluasi untuk setiap file\n",
    "for filename, summary in summaries.items():\n",
    "    print(f\"Ringkasan untuk {filename}:\\n{summary}\\n\")\n",
    "\n",
    "# Menampilkan hasil evaluasi\n",
    "print(f\"Precision: {sum(precision_all) / len(precision_all)}\")\n",
    "print(f\"Recall: {sum(recall_all) / len(recall_all)}\")\n",
    "print(f\"F1 Score: {sum(f1_all) / len(f1_all)}\")\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VDBQdrant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
